{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "\n",
    "In scikit the Decision Tree algorithm uses the CART algorithm. CART simply stands for Classification And Regression Tree. This doesn't really tell us much other than it is capable of performing both classification and regression functions.\n",
    "\n",
    "Regression we have already looked at when we used the specific Linear Regression Algorithm. We want to use the Decision Tree algorithm to create a classification model. \n",
    "\n",
    "By Classification we mean that from a set of feature values from an observation we want to place the the observation in to one class or another. We can have as many classifications as we want but often there is only two, making for a boolean decision.\n",
    "\n",
    "For example, customer churn , mortgage application acceptance (or not).\n",
    "\n",
    "For our example we are again going to use a dataset from scikit. In this case the Boston breast cancer dataset. The dataset has many features but the 'target' only has two classifications; 'Malignant' or 'Benign' (0 and 1).\n",
    "\n",
    "The process that we will follow, very closely mirrors the Regression approach. \n",
    "\n",
    "Much of the work we need to do occurs before we construct the model.\n",
    "\n",
    "The test we do afterwards to establish how good the model is, are somewhat different to what we used for Regression but are there for the same purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "print(cancer.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cancer = pd.DataFrame(cancer.data,columns=cancer.feature_names)\n",
    "df_cancer['target'] = pd.Series(cancer.target)\n",
    "#df_cancer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cancer.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values\n",
    "\n",
    "As with the Boston data there are no missing values for us to deal with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before we will create a few plots of the data to aid our understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only need the pyplot functions\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# needed by jupyter to ensure that the plots appear inline (in the usual output cell)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# both histograms ...\n",
    "for col in df_cancer.columns:\n",
    "    df_cancer[col].hist(bins = 20)\n",
    "    plt.title('Histogram of ' + col)\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ...   and boxplots can be useful\n",
    "\n",
    "for col in df_cancer.columns:\n",
    "    df_cancer.boxplot(column = col)\n",
    "    plt.title('Boxplot of ' + col)\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable correlations\n",
    "import seaborn as sns\n",
    "sns.pairplot(df_cancer)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can look at the correlation between each pair of variables\n",
    "\n",
    "corr = df_cancer.corr()\n",
    "\n",
    "# easier to see in a csv\n",
    "#corr.to_csv('cancer_corr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or graphically with a heatmap \n",
    "import seaborn as sns\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,12))\n",
    "heat_map = sns.heatmap(corr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers and Normalisation \n",
    "\n",
    "Do nothing! in this case.\n",
    "\n",
    "The box plots show some technical outliers but nothing isolated.\n",
    "\n",
    "Because a decision tree treats all of the preditors independently, there is not need to normalise the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Variables\n",
    "\n",
    "Some decision tree algorithms can deal with categoricgal values by potentially creating a split on each value. The CART algorithm on the other hand always uses a binary split and because of this it cannot (certainly in scikit implementation) deal with categorical values.\n",
    "\n",
    "In the case of the Cancer dataset, there are in fact no categorical values anyway. However if there were we would need to introduce dummy variables to deal with them.\n",
    "\n",
    "We shall have a slight digression to show how we could deal with this situation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in a dataset (very small)\n",
    "\n",
    "df_ratings = pd.read_csv('ratings.csv')\n",
    "df_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 'Rating' column has categorical values \n",
    "\n",
    "# We can create another dataframe which has columns for each of the different values in the 'Rating' column.\n",
    "# The number of rows in the dataframe will match the original and the values in the new columns will be \n",
    "# either 0 or 1 depending on whether one depending the original 'Rating' value.\n",
    "\n",
    "df_dummies = pd.get_dummies(df_ratings['Rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you need to create dummy variables for more than one column, it can be useful to name them with a prefix, \n",
    "# typically of the original column name\n",
    "\n",
    "df_dummies = pd.get_dummies(df_ratings['Rating'], prefix = 'Rating')\n",
    "df_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we want to combine the two dataframes and drop the original categorical column\n",
    "\n",
    "result = pd.concat([df_ratings, df_dummies], axis=1)\n",
    "result.drop(['Rating'], axis = 1, inplace=True)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data\n",
    "\n",
    "We will do this in a similar way as we did for regression, however because there is an in blaance inthe target values we will stratify the split on the target so as to ensure that both values are fairly represented in both the training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_cancer['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the predictors\n",
    "df_cancer_X = pd.DataFrame(df_cancer,columns=cancer.feature_names)\n",
    "#df_cancer_X.describe()\n",
    "# the tagets\n",
    "df_cancer_y = pd.DataFrame(df_cancer,columns=['target'])\n",
    "#df_boston_y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we cn use the train_test_split function from sklearn\n",
    "\n",
    "# We need to provide both the predictors and the target dataframes\n",
    "# We also provide a 'test_size' value to indicate the % of the rows to be used for the test datframe. \n",
    "#\n",
    "# Because there is an uneven split in the values of the target, we will use the stratify parameter in the train_test_split\n",
    "# function to ensure that each iis equallty represented in the test and train dataframes.\n",
    "\n",
    "from sklearn import model_selection\n",
    "\n",
    "#X_train, X_test, y_train, y_test = model_selection.train_test_split(df_cancer_X, df_cancer_y, test_size = 0.2, random_state = 42)\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(df_cancer_X, df_cancer_y, test_size = 0.2, random_state = 42, stratify = df_cancer_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get shape of test and training sets that have been created\n",
    "print('Training Set Row Count: ', X_train.shape[0])\n",
    "print('Test Set Row Count: ', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model\n",
    "\n",
    "In this example we are going to build a decisiontree model\n",
    "\n",
    "We are also importing export_graphviz function to help us visualise the created decisiontree.\n",
    "\n",
    "graphviz is an open source standa alone vizualisation product that you need to install. There are Windows, Mac and Linux versions available. You also need to install a couple of libraries into the Python environment\n",
    "\n",
    "#pip install graphviz\n",
    "\n",
    "#pip install pydotplus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree \n",
    "from sklearn.tree import export_graphviz\n",
    "#import pydotplus\n",
    "import graphviz\n",
    "\n",
    "model = tree.DecisionTreeClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can now fit the model\n",
    "\n",
    "model = model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can find out which features were used and how important they were to the model\n",
    "\n",
    "d = dict(zip(cancer.feature_names, model.feature_importances_))\n",
    "for key in d :\n",
    "    print(key, \":\", d[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use graphviz to create a picture of the model\n",
    "# The picture makes it very easy to understand the and explain the model. \n",
    "# in fact you could use it to make your own predictions.\n",
    "\n",
    "list_col = list(df_cancer.columns)\n",
    "list_col.remove('target')\n",
    "#dot_data = export_graphviz(model)\n",
    "graphviz.Source(export_graphviz(model,out_file=None, feature_names = list_col, impurity = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you may prefer to save the tree image as a pdf\n",
    "\n",
    "# to output to a .dot file\n",
    "with open(\"cancer_classifier.dot\", \"w\") as f:\n",
    "    f = tree.export_graphviz(model, out_file=f, feature_names = sorted(list_col))\n",
    "\n",
    "# Then us a command line instruction to generate the pdf in the local directory\n",
    "!dot -Tpdf cancer_classifier.dot -o cancer_classifier.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How good is the model?\n",
    "\n",
    "We are going to use two metrics to look at how the model is.\n",
    "\n",
    "A confusion matrix and the Receiver Operating Characteristic Area Under the Curve (ROC AUC)\n",
    "\n",
    "## What is a confusion matrix?\n",
    "\n",
    "A confusion matrix compare the number of correct prediction against the total number of predictions (i.e. number of test observations.)\n",
    "\n",
    "The confusion matrix is an n*n matrix where n is the number of values in the clasification. In our case there are only 2.\n",
    "\n",
    "<img src=\"Confusion_matrix.png\" />\n",
    "\n",
    "To calculate the accuracy of the model we sum the values in the diagonal cell and divide by the sum of the values in all of the cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = confusion_matrix(y_test,y_pred)\n",
    "print(cf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (cf[0,0] + cf[1,1])/(cf[0,0] + cf[0,1] + cf[1,0] + cf[1,1] )\n",
    "print(\"Accuracy of the model is : \", round(accuracy,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC_AUC\n",
    "\n",
    "# See https://en.wikipedia.org/wiki/Receiver_operating_characteristic \n",
    "# for details\n",
    "\n",
    "probabilities = model.predict_proba(X_train)\n",
    "fpra, tpra, threshold = roc_curve(y_train, probabilities[:,1])\n",
    "plt.title('ROC curve')\n",
    "plt.plot(fpra,tpra, 'b')\n",
    "plt.plot([0,1],[0,1], 'g--')\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1])\n",
    "plt.ylabel('True Positive rate')\n",
    "plt.xlabel('False Positive rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both of our measures seem to indicate excellent results for the model. \n",
    "\n",
    "However Decisiontrees are prone to overfitting\n",
    "\n",
    "Exercise: What is overfitting and what can you do about it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other models are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# 1 Create an object\n",
    "rfr = RandomForestRegressor()\n",
    "# 2 fit the model\n",
    "rfr.fit(X_train, y_train)\n",
    "\n",
    "# 3 try some predictions\n",
    "y_pred = rfr.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = confusion_matrix(y_test,y_pred.round())\n",
    "print(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (cf[0,0] + cf[1,1])/(cf[0,0] + cf[0,1] + cf[1,0] + cf[1,1] )\n",
    "print(\"Accuracy of the model is : \", round(accuracy,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
